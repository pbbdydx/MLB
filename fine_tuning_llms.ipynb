{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAdiazZl/lrRNm7yT2W7YO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pbbdydx/MLB/blob/main/fine_tuning_llms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ilBBQK3jcY1P",
        "outputId": "4a7f8b9b-aa7c-49e8-8d2d-eaa86b146f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-06 21:53:42--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.117.207, 173.194.202.207, 173.194.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.117.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   124MB/s    in 0.5s    \n",
            "\n",
            "2024-11-06 21:53:43 (124 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip dataset\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define paths\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Load images and labels\n",
        "x_data = []\n",
        "y_data = []\n",
        "image_size = (150, 150)  # Resize all images to 150x150\n",
        "\n",
        "# Load cat images\n",
        "cats_dir = os.path.join(train_dir, \"cats\")\n",
        "for img_name in os.listdir(cats_dir):\n",
        "    img_path = os.path.join(cats_dir, img_name)\n",
        "    img = Image.open(img_path).convert(\"RGB\").resize(image_size)\n",
        "    x_data.append(np.array(img))\n",
        "    y_data.append(1)  # Label for cats\n",
        "\n",
        "# Load dog images\n",
        "dogs_dir = os.path.join(train_dir, \"dogs\")\n",
        "for img_name in os.listdir(dogs_dir):\n",
        "    img_path = os.path.join(dogs_dir, img_name)\n",
        "    img = Image.open(img_path).convert(\"RGB\").resize(image_size)\n",
        "    x_data.append(np.array(img))\n",
        "    y_data.append(0)  # Label for dogs\n",
        "\n",
        "# Convert to numpy arrays\n",
        "x_data = np.array(x_data)\n",
        "y_data = np.array(y_data)\n",
        "\n",
        "# Split into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Load pre-trained ResNet50 model\n",
        "pretrained_model = tf.keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    input_shape=(150, 150, 3),\n",
        "    pooling='avg',\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Freeze the base model\n",
        "pretrained_model.trainable = False\n",
        "\n",
        "# Add custom classification layers\n",
        "model = tf.keras.Sequential([\n",
        "    pretrained_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification: 1 for cat, 0 for dog\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Fine-tuning: unfreeze some layers and re-train with a lower learning rate\n",
        "pretrained_model.trainable = True\n",
        "for layer in pretrained_model.layers[:-10]:  # Freeze earlier layers to avoid overfitting\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile with a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fine-tune the model\n",
        "fine_tune_history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXkYq42Hcmdu",
        "outputId": "06e713c4-7cc5-4d62-c725-44539da9307f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 4s/step - accuracy: 0.5164 - loss: 0.7742 - val_accuracy: 0.5425 - val_loss: 0.6858\n",
            "Epoch 2/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - accuracy: 0.5371 - loss: 0.6968 - val_accuracy: 0.5325 - val_loss: 0.6919\n",
            "Epoch 3/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3s/step - accuracy: 0.5433 - loss: 0.6877 - val_accuracy: 0.5700 - val_loss: 0.6738\n",
            "Epoch 4/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 3s/step - accuracy: 0.5428 - loss: 0.6861 - val_accuracy: 0.5600 - val_loss: 0.6745\n",
            "Epoch 5/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3s/step - accuracy: 0.5823 - loss: 0.6736 - val_accuracy: 0.5450 - val_loss: 0.6768\n",
            "Epoch 6/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 3s/step - accuracy: 0.5764 - loss: 0.6730 - val_accuracy: 0.5875 - val_loss: 0.6723\n",
            "Epoch 7/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - accuracy: 0.6112 - loss: 0.6652 - val_accuracy: 0.5725 - val_loss: 0.6726\n",
            "Epoch 8/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 3s/step - accuracy: 0.5874 - loss: 0.6694 - val_accuracy: 0.5650 - val_loss: 0.6692\n",
            "Epoch 9/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 3s/step - accuracy: 0.5799 - loss: 0.6621 - val_accuracy: 0.5650 - val_loss: 0.6674\n",
            "Epoch 10/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.6087 - loss: 0.6630 - val_accuracy: 0.5875 - val_loss: 0.6661\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 4s/step - accuracy: 0.5520 - loss: 0.8952 - val_accuracy: 0.5875 - val_loss: 0.6635\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - accuracy: 0.6350 - loss: 0.6505 - val_accuracy: 0.5625 - val_loss: 0.7064\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 4s/step - accuracy: 0.6972 - loss: 0.6129 - val_accuracy: 0.5375 - val_loss: 0.7904\n",
            "Epoch 4/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.6834 - loss: 0.5891 - val_accuracy: 0.5150 - val_loss: 0.9204\n",
            "Epoch 5/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.6905 - loss: 0.5834 - val_accuracy: 0.5075 - val_loss: 1.0684\n"
          ]
        }
      ]
    }
  ]
}